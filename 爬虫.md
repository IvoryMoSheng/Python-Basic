#爬虫
##基本思路summarize
1. 基本的爬虫工作原理
2. 基本的http抓取工具，scrapy
3. Bloom Filter: Bloom Filters by Example
4. 如果需要大规模网页抓取，你需要学习分布式爬虫的概念。其实没那么玄乎，你只要学会怎样维护一个所有集群机器能够有效分享的分布式队列就好。最简单的实现是python-rq: https://github.com/nvie/rq
5. rq和Scrapy的结合：darkrho/scrapy-redis · GitHub
6. 后续处理，网页析取(grangier/python-goose · GitHub)，存储(Mongodb)

----